# toxic-comments

### Warning!!! this notebook may contains some irrelevent texts since we are analysing TOXIC COMMENTS.

#### Contxext:

Kaggle was hosting a [competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) to build an nlp model to detect toxic behaviours in online plateforms, in order to protect the users from peopel who have some bad communication behaviour.

In this repository we will give one solution based on BERT (a SOTA model in language modeling) that have a good performance (more than 90% of F1 score). The code is presented in an notebook with some minor EDA.
